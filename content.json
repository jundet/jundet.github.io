{"meta":{"title":"GISTime","subtitle":null,"description":null,"author":"GISTime","url":"http://www.gistime.cn","root":"/"},"pages":[{"title":"","date":"2018-10-09T13:48:55.000Z","updated":"2018-10-09T13:50:20.000Z","comments":false,"path":"categories/index.html","permalink":"http://www.gistime.cn/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-10-09T13:48:23.000Z","updated":"2018-10-09T13:50:16.000Z","comments":false,"path":"tags/index.html","permalink":"http://www.gistime.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"支持向量机","slug":"svm","date":"2019-11-19T07:14:04.000Z","updated":"2019-11-20T06:35:02.779Z","comments":true,"path":"2019/11/19/svm/","link":"","permalink":"http://www.gistime.cn/2019/11/19/svm/","excerpt":"","text":"支持向量机（SVM）推荐讲解视频 白板推导 支持向量机的思想是寻找样本分类的最大间隔。 设样本$D=\\{(x_1,y_1),(x_1,y_1),…,(x_m,y_m)\\}$,其中$y_i \\in \\{+1,-1\\}$,当$x_i$为正例时$y_i=+1$，当$x_i$为反例时，$y_i=-1$. 线性可分支持向量机 线性可分支持向量机是最基本的支持向量机，分类超平面为 w^Tx+b=0 \\tag{1}当样本点为正例时$w^Tx_i+b\\ge 0,y_i=+1$,当样本点为反例时$w^Tx_i+b\\le 0,y_i=-1$,因此 y_i(w^Tx_i+b)\\ge 1 \\tag{2}样本点到超平面的距离 r_i=\\frac{|w^tx_i|+b}{||w||}两个边界之间的距离为 r=\\frac{2}{||w||}要获得最大间隔即求最大的r， \\begin{aligned} & \\max_{w,b}\\quad \\frac{2}{||w||}\\\\ & s.t.\\quad y_i(w^Tx_i+b)\\ge 1,\\quad i=1,2,...,m \\end{aligned}转化为最小化问题即 \\begin{aligned} & \\min_{w,b}\\quad \\frac{1}{2}{||w||^2}\\\\ & s.t.\\quad y_i(w^Tx_i+b)\\ge 1,\\quad i=1,2,...,m \\end{aligned} \\tag{3}式(3)即为支持向量机的基本型优化问题。 求得最优化问题的结$w^,b^$,得到线性可分支持向量机，分离超平面为 w^*x+b^*=0分类决策函数为 f(x)=sign(w^*x+b^*)对偶问题式(3)的拉格朗日乘子式是 L(w,b,\\lambda)=\\frac{1}{2}{||w||^2}+\\sum_{i=1}^{m}{\\lambda_i(1-y_i(w^Tx_i+b))} \\tag{4}对式(4)中$w,b$分别求偏导可得 \\frac{\\partial L}{\\partial b}=-\\sum_{i=1}^m\\lambda_i y_i\\\\ \\frac{\\partial L}{\\partial w}=w-\\sum_{i=1}^m\\lambda_iy_ix_i令$\\frac{\\partial L}{\\partial b},\\frac{\\partial L}{\\partial w}$为0可求得 \\sum_{i=1}^m\\lambda_i y_i=0\\\\ w=\\sum_{i=1}^m\\lambda_iy_ix_i \\tag{5}将式(5)代入$L(w,b,\\lambda)$中可得 \\begin{aligned} L(w,b,\\lambda)&=\\frac{1}{2}\\sum_{i=1}^m\\sum_{j=1}^m{\\lambda_i\\lambda_jy_iy_ix_i^Tx_i}+\\sum_{i=1}^{m}\\lambda_i-\\sum_{i=1}^m\\sum_{j=1}^m{\\lambda_i\\lambda_jy_iy_ix_i^Tx_i}\\\\ &=\\sum_{i=1}^{m}\\lambda_i-\\frac{1}{2}\\sum_{i=1}^m\\sum_{j=1}^m{\\lambda_i\\lambda_jy_iy_ix_i^Tx_i} \\end{aligned}即原问题式(3)的对偶问题为 \\begin{aligned} \\max_\\lambda \\quad & \\sum_{i=1}^{m}\\lambda_i-\\frac{1}{2}\\sum_{i=1}^m\\sum_{j=1}^m{\\lambda_i\\lambda_jy_iy_ix_i^Tx_i}\\\\ s.t.,\\quad & \\sum_{i=1}^m\\lambda_i y_i\\quad=0\\\\ &\\lambda_i\\ge0, \\quad i=1,2,...,m \\end{aligned} \\tag{6}注：此问题符合强对偶关系即 \\min_{w,b}\\max_\\lambda L(w,b,\\lambda)= \\max_\\lambda \\min_{w,b} L(w,b,\\lambda)注：$强对偶关系\\Leftrightarrow KKT$ 设$\\lambda^,w^,b^*$为最优解则有KKT条件： \\lambda_i^*(y_i(w^{*T}x+b^*)-1)=0 \\\\ y_i(w^{*T}x+b^*)-1\\ge 0\\\\ \\lambda_i^*\\ge 0其中$w^=\\sum_{i=1}^m\\lambda_i^ y_ix_i$,$b^=y_i-\\sum_{i=1}^m\\lambda_i^y_ix_i^Tx_j$ 软间隔在线性可分支持向量机中假设所有的样本能够完全被超平面加以区分，但实际的数据中会存在误差，解决这些误差的方法为使用损失函数。 最直接的损失函数为“0/1”损失函数，正确项为0，错误项为1，此时优化目标变为 \\min_{w,b}\\quad \\frac{1}{2}w^Tx +C\\sum_{i=1}^m \\ell_{0/1}(y_i(w^Tx_i+b)-1)其中$C$为缩放系数（超参数），$\\ell_{0/1}$为0/1损失函数。 由于$\\ell_{0/1}$不具有连续性，因此一般使用其他损失函数代替$\\ell_{0/1}$。 hinge（合页）损失：$\\ell_{hinge}=max\\{0,(y_i(w^Tx_i+b)-1)\\}$ 引入松弛变量$\\xi$，优化目标变为 \\begin{aligned} \\min_{w,b,\\xi}\\quad &\\frac{1}{2}||w||^2+C\\sum_{i=1}^m \\xi_i\\\\ s.t. \\quad &y_i(w^Tx_i+b)-1\\ge\\xi_i,\\\\ & \\xi_i\\ge0 \\end{aligned}\\tag{7}其对偶问题为 \\begin{aligned} \\max_\\lambda \\quad & \\sum_{i=1}^{m}\\lambda_i-\\frac{1}{2}\\sum_{i=1}^m\\sum_{j=1}^m{\\lambda_i\\lambda_jy_iy_ix_i^Tx_i}\\\\ s.t.,\\quad & \\sum_{i=1}^m\\lambda_i y_i\\quad=0\\\\ &C\\ge\\lambda_i\\ge0, \\quad i=1,2,...,m \\end{aligned} \\tag{8}非线性支持向量机通过非线性变换将样本转换到高维空间中在进行线性分类。在线性支持向量机学习的对偶问题中，目标函数只涉及样本间的内积，即$x_i^T x_j$。假设映射函数为$\\phi(x)$，则在高维空间中样本间内积为$\\phi(x_i^T)\\phi(x_j)$。令 K(i,j)=\\phi(x_i^T)\\phi(x_j)即用核函数$K(i,j)$代替原有内积。非线性支持向量机通过核化得到核线性判别分析（KLDA）。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"}]},{"title":"LDA与PDA","slug":"ldapca","date":"2019-11-14T07:45:45.000Z","updated":"2019-11-14T09:01:16.397Z","comments":true,"path":"2019/11/14/ldapca/","link":"","permalink":"http://www.gistime.cn/2019/11/14/ldapca/","excerpt":"","text":"线性判别分析（LDA）LDA是一种经典的线性学习方法，也称为“Fisher判别分析”。 LDA的基本思想：给定训练集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近，不同种类样例的投影点尽可能远。 为实现同类样例的投影点尽可能接近，可让同类样例投影点的协方差尽可能小。而实现不同种类样例的投影点尽可能远，则不同种类样例投影中心的距离尽可能大。 二分类问题同时实现以上两种情况则可最大化$J$. J= \\frac{\\|\\omega^T\\mu_0 - \\omega^T\\mu_1\\|_2^2}{\\omega^T \\Sigma_0\\omega + \\omega^T\\Sigma_1\\omega}\\\\ =\\frac{\\omega^T(\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^T\\omega}{\\omega^T(\\Sigma_0+\\Sigma_1)\\omega}其中$\\mu_i$为第i类的均值向量、$\\Sigma_i$为第i类的协方差矩阵，$\\omega$为投影直线。$\\omega^T\\mu_i$为第i类投影到$\\omega$上的投影中心，$\\omega^T \\Sigma_i\\omega$为第i类投影到$\\omega$上的协方差矩阵 设$S_\\omega$为类内散度矩阵 \\begin{aligned} S_\\omega&=\\Sigma_0+\\Sigma_1\\\\ &=\\sum_{x\\in X_0}(x-\\mu_0)(x-\\mu_0)^T + \\sum_{x\\in X_1}(x-\\mu_1)(x-\\mu_1)^T \\end{aligned}设$S_b$为类间散度矩阵 S_b=(\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^T则 J=\\frac{\\omega^TS_b\\omega}{\\omega^TS_\\omega\\omega}此时$J$就是LDA的最大化目标，即$S_b$与$S_\\omega$的广义瑞利商。 为求$\\omega$令$\\omega^TS_\\omega\\omega=1$,此时优化目标转变为 min_\\omega -\\omega^TS_b\\omega\\\\ s.t. \\omega^TS_\\omega\\omega=1由拉格朗日乘子式, S_b\\omega=\\lambda S_\\omega \\omega令$S_b\\omega=\\lambda(\\mu_0-\\mu_1)$则 \\omega=S_\\omega^{-1}(\\mu_0-\\mu_1)多分类问题假定存在N个类，且第i类示例数为$m_i$。 设全局散度矩阵为$S_t$ S_t=S_b+S_\\omega\\\\ =\\sum_{i=1}^{m}(x_i-\\mu)(x_i-\\mu)^T其中$\\mu$是所有示例的均值向量，此时 S_\\omega=\\sum_{i=1}^N S_{\\omega i}其中 S_{\\omega i}=\\sum_{x \\in X_i}(x-\\mu_i)(x-\\mu_i)^T则 S_b=S_t-S_\\omega\\\\ =\\sum_{i=1}^N m_i(x-\\mu_i)(x-\\mu_i)^T多分类的优化目标为 max_W \\frac{tr(W^TS_bW)}{tr(W^TS_\\omega W)}其中$W\\in R^{d\\times (N-1)}$, S_bW=\\lambda S_\\omega W$W$的闭式解则是$S_\\omega^{-1}S_b$的$d’$个最大非零广义特征值所对应的特征向量组成的矩阵。 LDA是一种经典的有监督降维技术，其流程为 1.计算类内散度矩阵$S_\\omega$ 2.计算类间散度矩阵$S_b$ 3.对$S_\\omega^{-1}S_b$进行特征分解 4.返回最大非零广义特征值对应的特征向量 主成分分析（PCA）PCA是一种典型的无监督降维方法。如果用一个超平面对所有样本进行恰当的描述，则超平面应满足的性质有： 最近重构性：样本点到这个超平面的距离都足够近。 最大可分性： 样本点在这个超平面上的投影尽可能分开。 从最大可分性分析，样本点$x_i$在超平面上的投影为$W^Tx_i$，为实现所有样本点的投影尽可能分开这一目标，则应该使投影后的样本点之间方差最大化。投影后样本点的方差为$\\sum_iW^Tx_ix_i^TW$,则最优化目标为 max_W tr(W^TXX^TW)\\\\ s.t. W^TW=I对上式使用拉格朗日乘子式可得 XX^T\\omega_i=\\lambda \\omega _i于是对$XX^T$进行特征分解，对特征值进行排序，取前$d’$个特征值对应的特征向量构成特征矩阵。 PCA的流程为 1.对所有样本进行中心化：$x_i\\gets x_i -\\mu$,其中$\\mu$是均值 2.计算样本的协方差矩阵$XX^T$ 3.对矩阵进行特征值分解 4.取最大的$d’$个特征值对应的特征向量构成特征矩阵（投影矩阵）。 输出投影矩阵 异同点比较相同点1、LDA与PCA都是典型的降维方法。 2、LDA与PCA都假设样本符合高斯分布。 3、LDA与PCA都应用可特征值分解 不同点1、LDA为有监督，PCA为无监督 2、PCA是去掉原有数据的冗余的维度，LDA是选择一个最佳的投影方向，使得投影后相同类别的数据分布紧凑，不同类别的数据尽量相互远离。 3、LDA最多可以降到k-1维（k是训练样本的类别数量，k-1是因为最后一维的均值可以由前面的k-1维的均值表示）；PCA无限制 4、LDA可能会过拟合数据。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"降维","slug":"降维","permalink":"http://www.gistime.cn/tags/降维/"}]},{"title":"PyTorch 分布式","slug":"distribute","date":"2019-11-11T08:27:55.000Z","updated":"2019-11-12T12:33:18.919Z","comments":true,"path":"2019/11/11/distribute/","link":"","permalink":"http://www.gistime.cn/2019/11/11/distribute/","excerpt":"","text":"PyTorch分布式训练目前分布式训练的方法中主要分为数据并行与模型并行两种方法，其中在大多实验中以数据并行为主。模型并行主要存在于工业应用中，一般模型较大、训练数据是学术实验中训练数据的几何倍数。 数据并行PyTorch中实现数据并行的方法主要有DataParallel 和distributed 两种方法。 DataParallel1torch.nn.DataParallel(Module) DataParallel可以实现数据的并行训练，默认会按照设定的batch size将数据平均分配到每个GPU上，假设在工作站A上共有4张GPU，设定batch size=32，此时每张卡上将会获得 size=32/4 =8 的数据量。 在前向传播中每张卡将分别计算前向传播的参数，在反向传播过程中会将梯度汇集到一张卡上计算其梯度下降。一般会将数据汇集到原始GPU中，因此会产生GPU负载不均衡的问题，常常会出现第一张卡会满负载而其他卡利用率仅为一半的情况。 盗张图 原图 DataParallel(Module) 官方文档 官方示例 1This container parallelizes the application of the given :attr:`module` bysplitting the input across the specified devices by chunking in the batchdimension (other objects will be copied once per device). In the forwardpass, the module is replicated on each device, and each replica handles aportion of the input. During the backwards pass, gradients from each replicaare summed into the original module. 实现方法1234567import torch.nn as nnmodel = Net()# 可直接指定需要使用GPU编号model = nn.DataParalle(model.cuda(), device_ids=[0, 1, 2, 3])# 或者使用CUDA_VISIBLE_DEVICES指定# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'# model = nn.DataParallel(model).cuda() 12345678for batch_idx, (imgs, ids) in enumerate(trainloader): # 数据也要由内存转到GPU内存中 imgs, ids = imgs.cuda(), ids.cuda() feature = model(imgs) loss = criterion_xent(feature, ids) optimizer.zero_grad() loss.backward() optimizer.step() 该使用方法在GPUs&lt;8时效果较好，在GPU数据较多时官方推荐使用多进程（multiprocessing）实现 distributed多机（节点）多卡训练 官方函数说明 官方教程 ImageNet数据集是一个里程碑式的数据集，很多模型都是此数据集上进行预训练然后进行到其他数据集进行训练。如何更快的使用此数据集训练模型，推荐阅读腾讯的4分钟训练ImageNet 在感叹腾讯的实力（GPU数量不是一般小实验室搞得起的，技术很强）之余，使用PyTorch在mnist数据集上进行小试牛刀。mnist在练习使用PyTorch时很有帮助，但在此处使用多机多卡进行训练时可能还不如单张卡。其主要原为mnist数据集本身很小，其训练时间短，多机多卡训练需要对数据进行划分并复制到不同的GPU上，划分所需的时间可能比真正训练的时间长。因此想要体现出多机多卡的优势请选择较大的模型和数据集，并将Batch size设置的大一些。 distributed 数据并行的几个细节 1、distribute的实现需要与多进行搭配1234import torch.multiprocessing as mpmp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))# main_worker 是训练的具体函数，下面将进行介绍 # nprocs 每个节点上GPU的个数 2、模型复制123import torchmodel = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])# 使用 DistributedDataParallel 函数将模型复制到GPU中 3、数据划分12345678910111213141516train_dataset = datasets.MNIST('data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]))if args.distributed: train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) # 使用DistributedSampler对数据集进行划分，例如batch size = 100，GPU=4，每张卡将分配到batch size = 25，此方法使用平均划分的方法，如有个性化需求需要自行实现数据划分else: train_sampler = Nonetrain_loader = torch.utils.data.DataLoader( train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, pin_memory=True, sampler=train_sampler)# train_sampler 为选取器，从train_dataset中按照train_sampler规则进行选取 完整代码请看mnist_train.py，此代码根据官方示例改写，启动方式与官方示例的方式相同 Github代码示例 官方示例1：https://github.com/seba-1511/dist_tuto.pth 官方示例2：https://github.com/pytorch/examples/tree/master/imagenet https://github.com/yangkky/distributed_tutorial 其他介绍： https://blog.csdn.net/zwqjoy/article/details/89415933 https://blog.csdn.net/m0_38008956/article/details/86559432 https://zhuanlan.zhihu.com/p/68717029 https://zhuanlan.zhihu.com/p/38949622 https://blog.csdn.net/u010557442/article/details/79431520 模型并行官方示例 基本用法 123456789101112131415161718192021222324252627import torchimport torch.nn as nnimport torch.optim as optimclass ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() # 将net1复制到GPU0上进行计算 self.net1 = torch.nn.Linear(10, 10).to('cuda:0') self.relu = torch.nn.ReLU() # 将net2复制到GPU1上进行计算 self.net2 = torch.nn.Linear(10, 5).to('cuda:1') def forward(self, x): x = self.relu(self.net1(x.to('cuda:0'))) return self.net2(x.to('cuda:1')) model = ToyModel()loss_fn = nn.MSELoss()optimizer = optim.SGD(model.parameters(), lr=0.001)optimizer.zero_grad()outputs = model(torch.randn(20, 10))labels = torch.randn(20, 5).to('cuda:1')loss_fn(outputs, labels).backward()optimizer.step() 上述代码中的net1和net1既可以简单的一层网络也可以是nn.Sequential生成的网络片段。这种基本方法会将输入数据先在GPU0上进行训练，然后在转移到GPU1上进行训练，可以发现，无论何时都只有一张卡在计算而另一张卡在等待。为解决此问题，PyTorch提供了Pipelining Inputs（流水线）的方法实现模型并行。 假设Batch size = 120。按照split_size=20对batch size进行进一步划分。当PyTorch异步启动CUDA操作时，该实现无需生成多个线程即可实现并发。 1234567891011121314151617181920212223class PipelineParallelResNet50(ModelParallelResNet50): def __init__(self, split_size=20, *args, **kwargs): super(PipelineParallelResNet50, self).__init__(*args, **kwargs) self.split_size = split_size def forward(self, x): splits = iter(x.split(self.split_size, dim=0)) s_next = next(splits) s_prev = self.seq1(s_next).to('cuda:1') ret = [] for s_next in splits: # A. s_prev runs on cuda:1 s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) # B. s_next runs on cuda:0, which can run concurrently with A s_prev = self.seq1(s_next).to('cuda:1') s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) return torch.cat(ret)","categories":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/categories/PyTorch/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/tags/深度学习/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/tags/PyTorch/"}]},{"title":"深度学习中的正则化","slug":"regularization","date":"2019-10-22T13:09:53.000Z","updated":"2019-11-21T14:34:58.119Z","comments":true,"path":"2019/10/22/regularization/","link":"","permalink":"http://www.gistime.cn/2019/10/22/regularization/","excerpt":"","text":"深度学习中的正则化在对训练数据进行训练的过程中很容易造成过拟合，从而降低模型的泛化能力1","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/categories/深度学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"神经网络","slug":"神经网络","permalink":"http://www.gistime.cn/tags/神经网络/"}]},{"title":"排序算法","slug":"sequence","date":"2019-10-18T05:43:52.000Z","updated":"2019-10-22T12:27:19.919Z","comments":true,"path":"2019/10/18/sequence/","link":"","permalink":"http://www.gistime.cn/2019/10/18/sequence/","excerpt":"","text":"常用排序算法的实现基本排序算法：冒泡，选择，插入，希尔，归并，快排 冒泡排序重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。 123456789101112131415def bubbleSort(data): ''' 冒泡排序 :param data: 原序列 :return: 升序排列后序列 ''' i = len(data) while i &gt; 0: j = 0 while j &lt; i-1: if data[j] &gt; data[j+1]: data[j], data[j+1] = data[j+1],data[j] j += 1 i -= 1 return data 选择排序重复的走访要排序的元素列，(升序)选出最小的元素与第一个元素交换，第二次选出除第一个元素外的最小的元素与第二个元素交换，直到所有排序完成结束。 123456789101112131415def selectionSort(data): ''' 选择排序 :param data: 原序列 :return: 升序排列后序列 ''' i = 0 while i &lt; len(data)-1: j = i while j &lt; len(data): if data[i] &gt; data[j]: data[i], data[j] = data[j], data[i] j += 1 i += 1 return data 插入排序创建一个空数组，从待排序的数组中依次选择一个元素，将该元素插入到新建数组的合适位置。 1234567891011121314151617181920def insertSort(data): ''' 插入排序 :param data: 原序列 :return: 升序排列后序列 ''' datatemp = [data[0]] for i in range(1, (len(data)-1)): for j in range(len(datatemp)): if data[i] &gt; datatemp[-1]: datatemp.append(data[i]) break elif data[i] &lt; datatemp[0]: datatemp.insert(0, data[i]) break elif datatemp[j] &lt; data[i] &lt; datatemp[j+1]: datatemp.insert(j+1, data[i]) break data = datatemp return data 希尔排序归并排序分治法，先原序列进行递归二分，在最后一层对两个元素进行排序，然后开始利用递归合并成排序后的序列。 123456789101112131415161718192021222324252627282930313233343536def mergeSort(data): ''' 归并排序 :param data: 原序列 :return: 升序排列后序列 ''' if len(data)&lt;=1: return data middle = len(data)//2 left = mergeSort(data[:middle]) right = mergeSort(data[middle:]) # 治 return merge(left, right)def merge(left,right): # 分 c = [] h = j = 0 while j&lt;len(left) and h&lt;len(right): if left[j]&lt;right[h]: c.append(left[j]) j+=1 else: c.append(right[h]) h+=1 if j==len(left): for i in right[h:]: c.append(i) if h==len(right): for i in left[j:]: c.append(i) return c 快速排序通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 12345678910111213141516171819202122232425def quickSort(data, p, r): ''' 快排排序 :param data: 原序列 :return: 升序排列后序列 ''' if p&lt;r: q = partition(data, p, r) quickSort(data, p, q-1) quickSort(data, q+1, r) return datadef partition(data, p, r): # 快速排序，原址重排 key = data[r] # 中间分割点 i = p-1 for j in range(p, r): if data[j] &lt;= key: i += 1 data[i], data[j] = data[j], data[i] data[i+1], data[r] = data[r], data[i+1] return i+1","categories":[{"name":"算法","slug":"算法","permalink":"http://www.gistime.cn/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.gistime.cn/tags/算法/"}]},{"title":"深度学习中的标准化","slug":"Normalization","date":"2019-10-18T01:50:06.000Z","updated":"2019-10-22T12:27:40.012Z","comments":true,"path":"2019/10/18/Normalization/","link":"","permalink":"http://www.gistime.cn/2019/10/18/Normalization/","excerpt":"","text":"深度学习中的标准化(Normalization)深度网络训练的问题假设网络没有非线性函数，不考虑偏置项，设每层网络层输入为$x^{(k-1)} \\in R^{n_{k-1}}$,参数为$W^{(k)}\\in R^{n_kn_{k-1}}$,输出为$x^{(k)}\\in R^{n_{k-1}}$,每一层的操作是 x^{(k)}=W^{(k)}x^{(k-1)}\\\\ = W^{(k)}W^{(k-1)}...W^{(1)}x^{(0)}梯度消失设$W=(0.5)$的元素值小于1，此时随着层数k的不断增加，w不断减少最终接近于0使得梯度下降非常缓慢造成梯度消失。 梯度爆炸设$W=(1.5)$的元素值大于1，此时随着层数k的不断增加，w不断增加最终接近于正无穷。使得梯度下降过大造成梯度爆炸。 使用激活函数可以限制每层输出值得输出范围在一定程度上消除梯度消失和梯度爆炸的影响。但是目前的激活函数中Sigmoid激活函数在经过多层后输出值会落在饱和区。从而减慢训练，ReLU激活函数克服了Sigmoid的缺点，增加了网络的稀疏性，但没有很好的解决梯度消失和梯度爆炸的影响。 Batch Normalization在同一个batch中的不同样本相同对应位置进行归一化。（将原有落在饱和区间的数据分布到标准正态分布上） 标准化公式为 \\hat{x_i}=\\frac{1}{\\sigma _i}(x_i-\\mu _i) \\tag{1}其中 \\mu _i = \\frac{1}{m}\\sum_{k\\in S_i}x_k, (均值)\\\\ \\sigma _i = \\sqrt{\\frac{1}{m}\\sum_{k\\in S_i}(x_k-\\mu _i)^2 +\\epsilon} ,(方差)其中$\\epsilon$是一个很小的正值，比如$10^{-8}$,这样可以强制避免$\\sqrt{z}$ 的梯度在z=0时未定义的问题。在测试阶段$\\mu$和$\\sigma$可以被替换为训练阶段收集的运行均值。这使得模型可以对单一样本评估，而无需使用定义与整个小批量的$\\mu$和$\\sigma$。 直接使用标准化公式会导致网络表达能力下降，为了防止这一点，每个神经元增加两个调节参数（scale和shift），这两个参数是通过训练来学习到的，用来对变换后数据再变换，使得网络表达能力增强，即对变换后的数据进行如下的scale和shift操作： y^{(k)}=\\gamma ^{(k)}\\hat{x}^{(k)}+\\beta ^{(k)} \\tag{2}通过公式（1）我们可以将输入数据分布到均值为1，方差为0的标准正态分布上。但是这样的操作会使得BN层后面的神经元无论怎么学习都会统一缩放到这一区域。使用公式（2）可以将经过标准化的数据分布到均值为$\\beta$方差为$\\gamma ^2$的区间上，而$\\beta$和$\\gamma$两个参数与其他训练参数相同，通过梯度下降的方式学得。这样BN层便能将输入数据缩放至最适合该神经元的区间（分布）上。在卷积神经网络中，数据维度为（N,C,H,W） 卷积层上的BN使用了类似权值共享的策略，把一整张特征图当做一个神经元进行处理。卷积神经网络经过卷积后得到的是一系列的特征图，网络某一层输入数据可以表示为四维矩阵(N,C,H,W)。在CNN中我们可以把每个特征图看成是一个特征处理（一个神经元），因此在使用Batch Normalization，mini-batch size 的大小就是：NHW，于是对于每个特征图都只有一对可学习参数：$\\beta$和$\\gamma$。相当于求取所有样本所对应的一个特征图的所有神经元的平均值、方差，然后对这个特征图神经元做归一化。 PyTorch中BatchNorm2d的实现公式 y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta优点 训练速度更快。因为网络的数据分布更加稳定，模型更易训练。 使用更大的学习率。因为网络的数据分布稳定，使用更大的学习率不会轻易造成损失函数曲线发散。能够加快训练的收敛速度。 不需要太关注模型参数的初始化。模型的随机初始化结果对模型的训练没有太大影响。 正则化效果。使用mini-batch的统计值近似训练数据的统计值，使得BN层具有正则化的效果 缺点 BN依赖于batch size, 对batch size敏感。当batch size太小时， batch的统计值不能代表训练的统计值，使得训练过程更加困难 在迁移学习fine-tune阶段，模型的BN层参数固定不变，这是不合理的因为迁移学习的预训练数据集和目标数据集有非常大的不同 不能用于测试阶段。测试阶段使用训练集的统计值取近似测试集的统计值是不合理的。 Group Normalization针对BN的一些缺点，Group Normalization 对channel进行分组，对每组channel进行Normalization","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/categories/深度学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/tags/深度学习/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/tags/PyTorch/"}]},{"title":"线性回归","slug":"linearmodel","date":"2019-09-24T01:46:53.000Z","updated":"2019-10-22T12:41:59.663Z","comments":true,"path":"2019/09/24/linearmodel/","link":"","permalink":"http://www.gistime.cn/2019/09/24/linearmodel/","excerpt":"","text":"线性回归一元线性回归给定数据集$D={(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}$试图学得线性回归$f(x_i)=wx_i+b$,使得$f(x_i)\\simeq y_i$ 采用均方差度量$f(x_i)$与$y_i$之间的差距，最小化均方差 (w^*,b^*)=\\arg min_{(w,b)}\\sum_{i=1}^m(f(x_i)-y_i)^2=\\arg min_{(w,b)}\\sum_{i=1}^m(y_i-wx_i-b)^2求解$w$和$b$使得$E_{(w,b)}=\\sum_{i=1}^m(y_i-wx_i-b)^2$最小化的过程，称为线性回归模型的最小二乘参数估计，对$w$和$b$分别求导可得到 \\frac{\\partial E_{(w,b)}}{\\partial w}=2(w\\sum_{i=1}^mx_i^2-\\sum_{i=1}^m(y_i-b)x_i) \\tag{1} \\frac{\\partial E_{(w,b)}}{\\partial b}=2(mb-\\sum_{i=1}^m(y_i-wx_i)) \\tag{2}令式（1）和式（2）为零可得到$w$和$b$的闭式解 w=\\frac{\\sum_{i=1}^my_i(x_i-\\bar{x})}{\\sum_{i=1}^mx_ix_i^2-{\\frac{1}{m}}(\\sum_{i=1}^mx_i)^2}\\\\ b=\\frac{1}{m}\\sum_{i=1}^m(y_i-wx_i)其中$\\bar{x}={\\frac{1}{m}}(\\sum_{i=1}^mx_i)$为$x$的均值。 多元线性回归$f(x_i)=w^Tx_i+b$使得$f(x_i)\\simeq y_i$。参数的向量化形式为$\\hat{w}=(w;b)$。最小化距离的向量形式为 \\hat{w}^*=\\arg min_{\\hat{w}}(y-X\\hat{w})^T(y-X\\hat{w})令$E_{\\hat{w}}=(y-X\\hat{w})^T(y-X\\hat{w})$,对$\\hat{w}$求导得到 \\frac{\\partial E_{(\\hat{w})}}{\\partial \\hat{w}}=xX^T(X\\hat{w}-y) \\tag{3}令式（3）为零可以求得$\\hat{w}$的最优解的闭式解。 当$X^TX$为满秩矩阵或正定矩阵时可得 \\hat{w}^*=(X^TX)^{-1}X^Ty其中$(X^TX)^{-1}$是矩阵$X^TX$的逆矩阵，令$\\hat{x}_i=(x_i;1)$,最终学得的多元线性回归模型为 f(\\hat{x}_i)=\\hat{x}^T_i(X^TX)^{-1}X^Ty当$X^TX$不是满秩矩阵时常常引入正则化项。 对数线性回归 \\ln{y}=w^Tx+b \\tag{4}式（4）实际上是在试图让$e^{w^Tx+b}$逼近$y$，虽然在形式上仍然是现象回归，但实质上实在求取输入空间到输出空间的非线性函数映射。 对数几率回归对数几率回归的实质是分类问题 对于二分类任务，使用阶跃函数将实值$z$转换为$0/1$值。一种单位阶跃函数如下所示 y=\\left\\{ \\begin{array}{ll} 0,&\\textrm{z0} \\end{array} \\right.单位阶跃函数不连续，因此不能直接使用，而对数几率函数单调可微，对数几率函数是一种“Sigmoid函数” y=\\frac{1}{1+e^{-(w^Tx+b)}}类似于式（4） \\ln \\frac{y}{1-y}=w^Tx+b若将$y$视为样本$x$作为正例的可能性，则$1-y$是其反例可能性，两者的比值称为几率，反应了$x$作为正例的可能性。对几率取对数可得到对数几率（logit）$\\ln \\frac{y}{1-y}$，因此使用线性回归模型的预测结果取逼近真是标记的对数几率，其模型称为对数几率回归。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"}]},{"title":"损失函数","slug":"loss","date":"2019-09-20T07:35:00.000Z","updated":"2019-11-19T07:14:46.001Z","comments":true,"path":"2019/09/20/loss/","link":"","permalink":"http://www.gistime.cn/2019/09/20/loss/","excerpt":"","text":"PyTorch中的损失函数1import torch.nn as nn PyTorch 官方文档 PyTorch中的损失函数有L1Loss、MSELoss、CrossEntropyLoss、NLLLoss、PoissonNLLLoss、KLDivLoss、BCELoss、BCEWithLogitsLoss、MarginRankingLoss、HingeEmbeddingLoss、MultiLabelMarginLoss、SmoothL1Loss、SoftMarginLoss、MultiLabelSoftMarginLoss、CosineEmbeddingLoss、MultiMarginLoss、TripletMarginLoss等损失函数。 L1LossCLASS torch.nn.L1Loss(size_average=None, reduce=None, reduction=’mean’) 计算差值的绝对值。 参数reduction可选项为‘none’、‘mean’、‘sum’。‘mean’返回平均值，‘sum’返回损失值之和。 其他两个参数已经弃用 MSELossCLASS torch.nn.MSELoss(size_average=None, reduce=None, reduction=’mean’) 计算差值的平方。 参数reduction可选项为none、mean、sum。mean返回平均值，sum返回损失值之和。 其他两个参数已经弃用 CrossEntropyLossCLASS torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction=’mean’) 计算交叉熵损失。 参数weighttenser，n个元素，代表n类的权重，当样本不平衡时使用会非常有用，默认为None 当weight=None时 loss(x,class)=-log{\\frac {e^{x[class]}}{\\sum_je^{x[j]}}}=-x[class]+log(\\sum_je^{x[j]})当weight被指定时 loss(s,class)=weights[class]*(-x[class]+log(\\sum_je^{x[j]}))reduction可选项为none、mean、sum。mean返回平均值，sum返回损失值之和。 TripletMarginLossCLASS torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction=’mean’) 计算三元组损失 L(a,p,n)=\\max\\{d(a_i,p_i)-d(a_i,n_i)+margin,0\\}其中$d(x_i,y_i)=||x_i-y_i||_p$ margin边界大小，默认为1 reduction可选项为none、mean、sum。mean返回平均值，sum返回损失值之和。 TripletSemihardLoss和TripletLoss的实现方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import torchfrom torch import nnfrom torch.nn import functional as Fclass TripletSemihardLoss(nn.Module): \"\"\" Shape: - Input: :math:`(N, C)` where `C = number of channels` - Target: :math:`(N)` - Output: scalar. \"\"\" def __init__(self, device, margin=0, size_average=True): super(TripletSemihardLoss, self).__init__() self.margin = margin self.size_average = size_average self.device = device def forward(self, input, target): y_true = target.int().unsqueeze(-1) same_id = torch.eq(y_true, y_true.t()).type_as(input) pos_mask = same_id neg_mask = 1 - same_id def _mask_max(input_tensor, mask, axis=None, keepdims=False): input_tensor = input_tensor - 1e6 * (1 - mask) _max, _idx = torch.max(input_tensor, dim=axis, keepdim=keepdims) return _max, _idx def _mask_min(input_tensor, mask, axis=None, keepdims=False): input_tensor = input_tensor + 1e6 * (1 - mask) _min, _idx = torch.min(input_tensor, dim=axis, keepdim=keepdims) return _min, _idx # output[i, j] = || feature[i, :] - feature[j, :] ||_2 dist_squared = torch.sum(input ** 2, dim=1, keepdim=True) + \\ torch.sum(input.t() ** 2, dim=0, keepdim=True) - \\ 2.0 * torch.matmul(input, input.t()) dist = dist_squared.clamp(min=1e-16).sqrt() pos_max, pos_idx = _mask_max(dist, pos_mask, axis=-1) neg_min, neg_idx = _mask_min(dist, neg_mask, axis=-1) # loss(x, y) = max(0, -y * (x1 - x2) + margin) y = torch.ones(same_id.size()[0]).to(self.device) return F.margin_ranking_loss(neg_min.float(), pos_max.float(), y, self.margin, self.size_average)class TripletLoss(nn.Module): \"\"\"Triplet loss with hard positive/negative mining. Reference: Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737. Code imported from https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py. Args: margin (float): margin for triplet. \"\"\" def __init__(self, margin=0.3, mutual_flag = False): super(TripletLoss, self).__init__() self.margin = margin self.ranking_loss = nn.MarginRankingLoss(margin=margin) self.mutual = mutual_flag def forward(self, inputs, targets): \"\"\" Args: inputs: feature matrix with shape (batch_size, feat_dim) targets: ground truth labels with shape (num_classes) \"\"\" n = inputs.size(0) # Compute pairwise distance, replace by the official when merged dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n) dist = dist + dist.t() dist.addmm_(1, -2, inputs, inputs.t()) dist = dist.clamp(min=1e-12).sqrt() # for numerical stability # For each anchor, find the hardest positive and negative mask = targets.expand(n, n).eq(targets.expand(n, n).t()) dist_ap, dist_an = [], [] for i in range(n): dist_ap.append(dist[i][mask[i]].max().unsqueeze(0)) dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0)) dist_ap = torch.cat(dist_ap) dist_an = torch.cat(dist_an) # Compute ranking hinge loss y = torch.ones_like(dist_an) loss = self.ranking_loss(dist_an, dist_ap, y) if self.mutual: return loss, dist return loss","categories":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/categories/PyTorch/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/tags/深度学习/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/tags/PyTorch/"},{"name":"loss","slug":"loss","permalink":"http://www.gistime.cn/tags/loss/"}]},{"title":"transform","slug":"transform","date":"2019-09-20T01:58:25.000Z","updated":"2019-09-24T04:06:11.807Z","comments":true,"path":"2019/09/20/transform/","link":"","permalink":"http://www.gistime.cn/2019/09/20/transform/","excerpt":"","text":"PyTorch数据处理之transforms1from torchvision import transforms PyTorch 官方文档 transforms主要应用于数据的预处理阶段。PIL Image是PyTorch中默认读取图像的方式，torchvision.transforms在图像处理中主要分为4类。 裁剪——Crop中心裁剪：transforms.CenterCrop随机裁剪：transforms.RandomCrop随机长宽比裁剪：transforms.RandomResizedCrop上下左右中心裁剪：transforms.FiveCrop上下左右中心裁剪后翻转，transforms.TenCrop 翻转和旋转——Flip and Rotation依概率p水平翻转：transforms.RandomHorizontalFlip(p=0.5)依概率p垂直翻转：transforms.RandomVerticalFlip(p=0.5)随机旋转：transforms.RandomRotation 图像变换resize：transforms.Resize标准化：transforms.Normalize转为tensor：transforms.ToTensor填充：transforms.Pad修改亮度、对比度和饱和度：transforms.ColorJitter转灰度图：transforms.Grayscale线性变换：transforms.LinearTransformation()仿射变换：transforms.RandomAffine依概率p转为灰度图：transforms.RandomGrayscale将数据转换为PILImage：transforms.ToPILImagetransforms.Lambda：添加用户自定义的处理过程 随机处理transforms.RandomChoice(transforms)：从给定的一系列transforms中选一个进行操作transforms.RandomApply(transforms, p=0.5)：给一个transform加上概率，依概率进行操作transforms.RandomOrder：将transforms中的操作随机打乱 常用方法transforms.Resizeclass torchvision.transforms.Resize(size, interpolation=2) 将输入的PIL图像缩放至size的分辨率 size：（输入类型为int或者sequence ）需要输出的图像大小 interpolation：采样（插值）方式（输入类型为int）。默认为PIL.Image.BILINEAR 可选项：PIL.Image.NEAREST、PIL.Image.BILINEAR、PIL.Image.BICUBIC、PIL.Image.LANCZOS、PIL.Image.HAMMING、PIL.Image.BOX transforms.Normalizeclass torchvision.transforms.Normalize(mean, std, inplace=False) 使用平均或标准差标准化。其作用就是先将输入归一化到(0,1)，再使用公式”(x-mean)/std”，将每个元素分布到(-1,1) 123transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])tensor.sub_(mean[:, None, None]).div_(std[:, None, None]) transforms.ToTensorCLASS torchvision.transforms.ToTensor 将PIL.image或者numpy.ndarray转为tensor 将PIL.image或者numpy.ndarray(H x W x C) [0, 255]转换为 torch.FloatTensor(C x H x W) [0.0, 1.0]","categories":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/categories/PyTorch/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/tags/深度学习/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/tags/PyTorch/"}]},{"title":"优化器","slug":"Optimizer","date":"2019-09-19T00:50:00.000Z","updated":"2019-09-25T07:28:54.850Z","comments":true,"path":"2019/09/19/Optimizer/","link":"","permalink":"http://www.gistime.cn/2019/09/19/Optimizer/","excerpt":"","text":"PyTorch中的优化器1import torch.optim as optim PyTorch提供个多个优化器，其中常用的有SGD、ASGD、RMSprop、Adam等。 SGDCLASS torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False) 随机梯度下降 参数params(iterable)待优化参数的iterable或者是定义了参数组的dict lr(float)学习率 momentum(float)动量因子（默认为0） dampening(float)动量的抑制因子（默认为0） nesterov(bool)使用Nesterov动量（默认为False） \\begin{aligned} &Require:学习率\\varepsilon,动量\\alpha \\\\ &Require:初始参数\\theta,初始速度v \\\\ &while 没有达到停止准则do\\\\ &从训练集中采用包含m个样本\\{x^1,...,x^m\\}的小批量，对应目标为y^i\\\\ &应用临时更新:\\widetilde{\\theta} \\gets\\theta +\\alpha v\\\\ &计算梯度(在临时点):g\\gets \\frac{1}{m}\\nabla_{\\widetilde{\\theta}}\\sum_i L(f(x^i;\\widetilde{\\theta}),y^i)\\\\ &计算速度更新:v\\gets \\alpha v-\\varepsilon g\\\\ &应用更新:\\theta \\gets \\theta+v\\\\ &end while \\end{aligned}ASGDclass torch.optim.ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)[source] 平均随机梯度下降 参数params(iterable)待优化参数的iterable或者是定义了参数组的dict lr(float)学习率，默认为（1e-2） lambd(float)衰减项，默认为（1e-4） alpha(float)eta更新指数，默认为0.75 t0(float)指明在哪一次开始平均化，默认为（1e6） weight_decay(float)权重衰减（L2惩罚）默认为0 Adamclass torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0) 来源于adaptive moments 参数params (iterable)待优化参数的iterable或者是定义了参数组的dict lr (float, 可选) 学习率（默认：1e-3） betas (Tuple[float, float], 可选) 用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999） eps (float, 可选) 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8） weight_decay (float, 可选) 权重衰减（L2惩罚）（默认: 0） \\begin{aligned} &Require:步长\\varepsilon(建议默认为0.001) \\\\ &Require:矩估计的指数衰减速度，\\rho_1和\\rho_2在区间[0,1]zhong (建议默认为[0.9,0.999]) \\\\ &Require:用于数值稳定的小常熟\\delta(建议默认为1e-8) \\\\ &Require:初始参数\\theta;\\\\ & 初始化一阶矩和二阶矩变量s=0,r=0;\\\\ & 初始化时间步t=0;\\\\ &while 没有达到停止准则do\\\\ &从训练集中采用包含m个样本\\{x^1,...,x^m\\}的小批量，对应目标为y^i\\\\ &计算梯度:g\\gets \\frac{1}{m}\\nabla_{\\widetilde{\\theta}}\\sum_i L(f(x^i;\\widetilde{\\theta}),y^i)\\\\ &t\\gets t+1\\\\ &更新有偏一阶矩估计:s\\gets \\rho_1s+(1-\\rho_1)g\\\\ &更新有偏二阶矩估计:s\\gets \\rho_1r+(1-\\rho_2)g\\odot g\\\\ &修正一阶矩的偏差:\\hat{s}\\gets \\frac{s}{a-\\rho_1^t}\\\\ &修正二阶矩的偏差:\\hat{r}\\gets \\frac{s}{a-\\rho_2^t}\\\\ &计算更新:\\Delta\\theta=-\\varepsilon \\frac{\\hat{s}}{\\sqrt{\\hat{r}+\\delta}}\\\\ &应用更新:\\theta \\gets \\theta+\\Delta\\theta\\\\ &end while \\end{aligned}","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/categories/深度学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/tags/深度学习/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://www.gistime.cn/tags/PyTorch/"}]},{"title":"神经网络反向传播","slug":"network","date":"2019-09-04T08:14:18.000Z","updated":"2019-11-19T08:46:30.532Z","comments":true,"path":"2019/09/04/network/","link":"","permalink":"http://www.gistime.cn/2019/09/04/network/","excerpt":"","text":"误差逆传播算法摘自机器学习-西瓜书-周志华 部分内容为个人理解 给定训练集$D={(x_1,y_1),(x_2,y_2),…,(x_m,y_m)},x_i \\in R^d,y_i\\in R^l$,即输入示例由$d$个属性描述，输出$l$维实值向量。多层前馈网络结构拥有$d$个输入神经元、$l$个输出神经元、$q$个隐层神经元，其中输出层第$j$个神经元的阈值用$\\theta_j$表示，隐层第$h$个神经元的阈值用$\\gamma_h$表示。输入层第$i$个神经元与隐层第$h$个神经元之间的连接权（权重）为$\\nu_{ih}$，隐层第$h$个神经元与输出层第$j$个神经元之间的连接权为$\\omega_{hj}$。记隐层第$h$个神经元接收到的输入为$\\alpha_h=\\sum_{i=1}^d\\nu_{ih}x_i$,输出层第$j$个神经元接收到的输入为$\\beta_j=\\sum_{h=1}^q\\omega_{hj}b_h$,其中$b_n$为隐层第$h$个神经元的输出。假设隐层和输出层神经元都是用$Sigmoid$函数。对训练例$(x_k,y_k)$，假定神经网络的输出为$\\hat y_k = (\\hat y^k_1,\\hat y^k_2,…,\\hat y^k_l)$,即 \\hat y^k_j = f(\\beta_j - \\theta_j) \\tag{1}则网络在$（x_k，y_k）$上的均方误差为 E_k=\\frac{1}{2} \\sum^l_{j=1}({\\hat y^k_j} - y^k_j)^2 \\tag{2} 前项传播过程输入层输入 $x_1,x_2,…,x_m$ 隐层输入 $\\alpha_h=\\sum_{i=1}^d\\nu_{ih}x_i$ 隐层输出$b_h= f(\\alpha_h-\\gamma_h)$ 输出层输入 $\\beta_j=\\sum_{h=1}^q\\omega_{hj}b_h$ 输出层输出 $\\hat y^k_j = f(\\beta_j - \\theta_j)$ 其中$f(\\cdot)$为激活函数，文中使用$Sigmoid$函数 $Sigmoid(x) = \\frac{1}{1+e^{-x}}$ 参数计算网络中需要计算的参数总数为$(d+l+1)q+l$,输入层到隐层的$d\\times q$个权重值，隐层到输出层的$q\\times l$个权重值，$q$个隐层神经元的阈值、$l$个输出层神经网络的阈值。 反向传播过程任意参数$\\nu$的更新估计式为 \\nu \\gets \\nu + \\Delta\\nuBP算法基于梯度下降策略，以目标的负梯度方向对参数进行调整，对式(2)的误差$E_k$，给定学习率$\\eta$,有 \\Delta\\omega_{hj} = -\\eta \\frac{\\partial E_k}{\\partial\\omega_{hj}} \\tag{3}注意到$\\omega_{hj}$先影响到$j$个输出层神经元的输入值$\\beta_j$，在影响到其输出值$\\hat y^k_j$,然后在影响到$E_k$,有 \\frac{\\partial E_k}{\\partial\\omega_{hj}} = \\frac{\\partial E_k}{\\partial\\hat y^k_j}\\cdot\\frac{\\partial \\hat y^k_j}{\\partial\\beta_j}\\cdot\\frac{\\partial \\beta_j}{\\partial\\hat y^k_j} \\tag{4}根据$\\beta_j$的定义显然有 \\frac{\\partial \\beta_j}{\\partial\\hat y^k_j} = b_n \\tag{5}$Sigmoid$函数有一个很好的性质： f^{'}(x)=f(x)(1-f(x))令$g_j=-\\frac{\\partial E_k}{\\partial\\hat y^k_j}\\cdot\\frac{\\partial \\hat y^k_j}{\\partial\\beta_j}$ ,则 \\begin{aligned} g_j&=-\\frac{\\partial E_k}{\\partial\\hat y^k_j}\\cdot\\frac{\\partial \\hat y^k_j}{\\partial\\beta_j} \\\\ &=-(\\hat y^k_j-y^k_j)f^{'}(\\beta - \\theta_j)\\\\ &= \\hat y^k_j(1-\\hat y^k_j)(y^k_j-\\hat y^k_j) \\end{aligned}\\tag{6}将式(6)和式(5)代入式(4)，再代入式(3)可以得到： \\Delta\\omega_hj = \\eta g_jb_h类似的可以得到 \\Delta\\theta_j=-\\eta g_j \\Delta \\nu_ih = \\eta e_hx_i \\Delta\\gamma_h=-\\eta e_h其中 \\begin{aligned} e_h&=-\\frac{\\partial E_k}{\\partial b_h}\\cdot\\frac{\\partial b_h}{\\partial\\alpha_h}\\\\ &=-\\sum^l_{j=1}\\frac{\\partial E_k}{\\partial \\beta_j}\\cdot\\frac{\\partial \\beta_j}{\\partial b_h}f^{'}(\\alpha_h-\\gamma_h)\\\\ &=\\sum^l_{j=1}\\omega_{hj}g_jf^{'}(\\alpha_h-\\gamma_h)\\\\ &=b_h(1-b_h)\\sum^l_{j=1}\\omega_{hj}g_j \\end{aligned}","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.gistime.cn/categories/深度学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"神经网络","slug":"神经网络","permalink":"http://www.gistime.cn/tags/神经网络/"}]},{"title":"Django 使用教程","slug":"Django ","date":"2019-01-29T03:19:53.000Z","updated":"2019-01-29T07:22:11.661Z","comments":true,"path":"2019/01/29/Django /","link":"","permalink":"http://www.gistime.cn/2019/01/29/Django /","excerpt":"","text":"示例1：安装Django并创建简单项目详情见https://docs.djangoproject.com/zh-hans/2.1/intro/tutorial01/ 环境基础为windows10+anaconda3 1、安装Django（版本2.1.5）1pip install Django==2.1.5 2、查看版本1python -m django --version 3、创建项目1django-admin startproject mysite 12345678项目的目录结构mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 目录说明 mysite：项目名，项目的容器。 manage.py:项目启动入口，用于与django内部进行交互 init.py:初始化文件 settings.py:项目配置信息 urls.py:项目中webapi的路由配置 wsgi.py:一个 WSGI 兼容的 Web 服务器的入口 4、启动项目1python manage.py runserver 默认端口为127.0.0.1:8080,可以在runserver后添加自拟端口 5、创建应用1python manage.py startapp polls 6、创建视图在polls/views.py中修改代码为： 1234from django.http import HttpResponsedef index(request): return HttpResponse(\"Hello, world. You're at the polls index.\") 在polls文件夹下创建urls.py并添加代码 123456from django.urls import pathfrom . import viewsurlpatterns = [ path('', views.index, name='index'),] 在mysite/urls.py中修改代码为 1234567from django.contrib import adminfrom django.urls import include, pathurlpatterns = [ path('polls/', include('polls.urls')), path('admin/', admin.site.urls),] 运行 python manage.py runserver 并访问 localhost:8000/polls(不是 localhost:8000)，将会看到Hello, world. You’re at the polls index. 示例2：","categories":[{"name":"编程","slug":"编程","permalink":"http://www.gistime.cn/categories/编程/"}],"tags":[{"name":"前端开发","slug":"前端开发","permalink":"http://www.gistime.cn/tags/前端开发/"}]},{"title":"Video Person Re-Identification","slug":"video person reid","date":"2018-11-14T10:37:53.000Z","updated":"2019-01-29T03:17:57.657Z","comments":true,"path":"2018/11/14/video person reid/","link":"","permalink":"http://www.gistime.cn/2018/11/14/video person reid/","excerpt":"","text":"Paper Datasets Code1 Code2 Leaderboard rank1/mAP iLIDS-VID PRID2011 MARS DukeMTMC-VideoReID SCAN 88.0/89.9 95.3/95.8 87.2/77.2 / Co-attention 85.4/87.8 93.0/94.5 86.3/76.1 / 3DCNN&amp;Non-local 81.3 91.2 84.3/77.0 / STAN 80.2/ 93.2/ 82.3/65.8 / RQEN 77.1/ 91.8/ 77.83/71.14 / (RQEN)Region-based Quality Estimation Network for Large-scale Person Re-identificationpaper:https://arxiv.org/abs/1711.08766 code:https://github.com/sciencefans/Quality-Aware-Network (ATAN)Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identificationpaper:https://arxiv.org/abs/1803.09882 (Co-attention)Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embeddingpaper:http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Video_Person_Re-Identification_CVPR_2018_paper.pdf (3DCNN&amp;Non-local)Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attentionpaper: https://arxiv.org/abs/1807.05073 SCAN: Self-and-Collaborative Attention Network for Video Person Re-identificationpaper:https://arxiv.org/abs/1807.05688 Revisiting Temporal Modeling for Video-based Person ReIDpaper:https://arxiv.org/abs/1805.02104 code:https://github.com/jundet/Video-Person-ReID","categories":[{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/categories/行人再识别/"}],"tags":[{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/tags/行人再识别/"}]},{"title":"机器学习课程——糖尿病预测","slug":"MLclass","date":"2018-10-25T13:36:57.000Z","updated":"2019-04-20T07:13:19.076Z","comments":true,"path":"2018/10/25/MLclass/","link":"","permalink":"http://www.gistime.cn/2018/10/25/MLclass/","excerpt":"","text":"机器学习课程——糖尿病预测 code 具体流程为 数据预处理 模型构建 实验结果 1、数据预处理 对数据集进行划分和归一化等常规操作后观察到两种类别存在不平衡的问题，这会对模型的训练产生偏差。为了解决该问题使用生成对抗网络（GAN）进行训练并产生新的数据加入到训练数据集中以平衡两种类别。生成对抗网络（GAN）能够学习到原有数据集的分布情况，产生的数据能与原有数据保持相同的分布即新的数据可以在一定程度（GAN的设计与训练的好坏）上认为是真实的样本。 2、模型构建1、分别使用神经网络（NN）、随机树（ET）、逻辑回归（Logistic）、支持向量机（SVM）、GradientBoosting（gdbt）、AdaBoost、XGBoost、LightGBM、CatBoost等模型对数据集进行训练和测试。 2、尝试使用单模型进行融合，使用融合后的模型对数据进行训练和测试。模型融合使用多数投票分类器。 融合 3、实验结果 模型融合 神经网络 CatBoost accuracy 83.1% 82.1% 82.4% F1-score 72.0% 70.2% 70.6% 模型融合 模型融合(GAN)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.gistime.cn/tags/机器学习/"},{"name":"生成对抗网络","slug":"生成对抗网络","permalink":"http://www.gistime.cn/tags/生成对抗网络/"}]},{"title":"基于局部和精细化分割的行人重识别","slug":"PCB","date":"2018-10-15T10:37:53.000Z","updated":"2018-10-25T09:00:18.000Z","comments":true,"path":"2018/10/15/PCB/","link":"","permalink":"http://www.gistime.cn/2018/10/15/PCB/","excerpt":"","text":"(PCB+RPP)Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline) Paper,code1,code2 Market1501： rank1：93.8，mAP：81.6 PCB（Part-based Convolutional Baseline）：基于局部信息能够获得细粒度特征，对人体的水平分割比较符合人体分布，在一定程度上保护有效信息源，使其不被割裂。 RPP（Refined Part Pooling）：实现了人体分割中的软分割，在原有水平分割的基础上再进行相应训练，融入对抗训练的思想使的再分割后的图像更加符合细粒度的特征提取，有效的解决了硬性分割带来的有效信息割裂的问题，保证了信息的完整性。 相关解读1 相关解读2","categories":[{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/categories/行人再识别/"}],"tags":[{"name":"多尺度","slug":"多尺度","permalink":"http://www.gistime.cn/tags/多尺度/"},{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/tags/行人再识别/"},{"name":"soft-attention","slug":"soft-attention","permalink":"http://www.gistime.cn/tags/soft-attention/"}]},{"title":"学习多粒度显著特征用于跨境追踪技术","slug":"MGN","date":"2018-10-10T04:37:53.000Z","updated":"2018-10-10T05:11:22.000Z","comments":true,"path":"2018/10/10/MGN/","link":"","permalink":"http://www.gistime.cn/2018/10/10/MGN/","excerpt":"","text":"(MGN)Learning Discriminative Features with Multiple Granularity for Person Re-Identification 视频介绍 ,Paper,code1,code2 Market1501： rank1：95.7，mAP：86.9 利用多粒度实现了对全局和局部信息特征的同时提取。其中全局特征模块中对人的整体特征进行的提取可以更好的关注人的整体结构，对图片进行2分和3分的分割对人的局部信息进行提取。该网络依赖ResNet，ResNet大大提高了准确率（ResNet50本身可以达到 Market1501： rank1：89.13，mAP：73.5） 多粒度的思想能充分提取特征。","categories":[{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/categories/行人再识别/"}],"tags":[{"name":"多尺度","slug":"多尺度","permalink":"http://www.gistime.cn/tags/多尺度/"},{"name":"行人再识别","slug":"行人再识别","permalink":"http://www.gistime.cn/tags/行人再识别/"}]},{"title":"算法导论","slug":"算法导论","date":"2018-10-08T13:36:57.000Z","updated":"2019-01-29T03:17:57.677Z","comments":true,"path":"2018/10/08/算法导论/","link":"","permalink":"http://www.gistime.cn/2018/10/08/算法导论/","excerpt":"","text":"算法导论第一章 算法在计算中的应用1.2 作为一种技术的算法练习1.2-2 插入排序运行步数为$8n^2$步，而归并排序运行$64nlgn$ 步，问对哪些n值，插入排序优于归并排序？ $8n^2 &lt; 64nlgn$，n=2,3 1.2.3 n最小值为何值时，运行时间为$100n^2$的一个算法在相同机器上快于运行时间为$2^n$ 的另一个算法？ $100n^2 &lt; 2^n$,n=15 思考题1-1 （运行时间比较）假设求解问题的算法需要$f(n)$ 毫秒，对下表中每个函数$f(n)$ 和时间t，确定可以在时间t内求解的问题的最大规模n。 1秒钟 1分钟 1小时 1天 1月 1年 1世纪 $lgn$ $10^4$ $6\\times 10^5$ $3.6\\times 10^7$ $8.64\\times10^8$ $2.592\\times10^{10}$ $3.1536\\times10^{11}$ $3.1536\\times10^{13}$ $\\sqrt{n}$ $10^6$ $n$ $10^3$ $nlgn$ 386 $n^2$ 31 $n^3$ 10 $2^n$ 9 $n!$ 6 第二章 算法基础2.1 插入排序伪代码123456789INSERTION-SORT(A)for j = 2 to A.length key = A[j] //inster A[j] into the sorted sequence A[1..j-1] i = j-1 while i&gt;0 and A[i]&gt;key A[i+1] = A[i] i = i-1 A[j+1] = key python 实现123456789def insertion_sort(A): for j in range(1,len(A)): key = A[j] i = j-1 while i&gt;-1 and A[i]&gt;key: A[i+1] = A[i] i -= 1 A[i+1] = key return A 练习2.1-2 重写INSERTION-SORT，使之按降序排序。 123456789def insertion_sort(A): for j in range(1,len(A)): key = A[j] i = j-1 while i&gt;-1 and A[i]&lt;key: # 将原来的A[i]&gt;k改为 A[i]&lt;k A[i+1] = A[i] i -= 1 A[i+1] = keyreturn A 2.1-3 考虑以下查找问题： 输入：n个数的一个序列A=","categories":[{"name":"算法","slug":"算法","permalink":"http://www.gistime.cn/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.gistime.cn/tags/算法/"}]}]}
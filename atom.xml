<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>GISTime</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.gistime.cn/"/>
  <updated>2019-09-05T05:02:57.424Z</updated>
  <id>http://www.gistime.cn/</id>
  
  <author>
    <name>GISTime</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>神经网络反向传播</title>
    <link href="http://www.gistime.cn/2019/09/04/network/"/>
    <id>http://www.gistime.cn/2019/09/04/network/</id>
    <published>2019-09-04T08:14:18.000Z</published>
    <updated>2019-09-05T05:02:57.424Z</updated>
    
    <content type="html"><![CDATA[<h1 id="误差逆传播算法"><a href="#误差逆传播算法" class="headerlink" title="误差逆传播算法"></a>误差逆传播算法</h1><p>摘自机器学习-西瓜书-周志华</p><p>部分内容为个人理解</p><p>给定训练集$D={(x_1,y_1),(x_2,y_2),…,(x_m,y_m)},x_i \in R^d,y_i\in R^l$,即输入示例由$d$个属性描述，输出$l$维实值向量。多层前馈网络结构拥有$d$个输入神经元、$l$个输出神经元、$q$个隐层神经元，其中输出层第$j$个神经元的阈值用$\theta_j$表示，隐层第$h$个神经元的阈值用$\gamma_h$表示。输入层第$i$个神经元与隐层第$h$个神经元之间的连接权（权重）为$\nu_{ih}$，隐层第$h$个神经元与输出层第$j$个神经元之间的连接权为$\omega_{hj}$。记隐层第$h$个神经元接收到的输入为$\alpha_h=\sum_{i=1}^d\nu_{ih}x_i$,输出层第$j$个神经元接收到的输入为$\beta_j=\sum_{h=1}^q\omega_{hj}b_h$,其中$b_n$为隐层第$h$个神经元的输出。假设隐层和输出层神经元都是用$Sigmoid$函数。对训练例$(x_k,y_k)$，假定神经网络的输出为$\hat y_k = (\hat y^k_1,\hat y^k_2,…,\hat y^k_l)$,即</p><script type="math/tex; mode=display">\hat y^k_j = f(\beta_j - \theta_j) \tag{1}</script><p>则网络在$（x_k，y_k）$上的均方误差为</p><script type="math/tex; mode=display">E_k=\frac{1}{2} \sum^l_{j=1}({\hat y^k_j} - y^k_j)^2 \tag{2}</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2019/09/04/network/1.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="前项传播过程"><a href="#前项传播过程" class="headerlink" title="前项传播过程"></a>前项传播过程</h2><p>输入层输入 $x_1,x_2,…,x_m$</p><p>隐层输入 $\alpha_h=\sum_{i=1}^d\nu_{ih}x_i$</p><p>隐层输出$b_h= f(\alpha_h-\gamma_h)$</p><p>输出层输入 $\beta_j=\sum_{h=1}^q\omega_{hj}b_h$</p><p>输出层输出 $\hat y^k_j = f(\beta_j - \theta_j)$</p><p>其中$f(\cdot)$为激活函数，文中使用$Sigmoid$函数</p><p>$Sigmoid(x) = \frac{1}{1+e^{-x}}$</p><h2 id="参数计算"><a href="#参数计算" class="headerlink" title="参数计算"></a>参数计算</h2><p>网络中需要计算的参数总数为$(d+l+1)q+l$,输入层到隐层的$d\times q$个权重值，隐层到输出层的$q\times l$个权重值，$q$个隐层神经元的阈值、$l$个输出层神经网络的阈值。</p><h2 id="反向传播过程"><a href="#反向传播过程" class="headerlink" title="反向传播过程"></a>反向传播过程</h2><p>任意参数$\nu$的更新估计式为</p><script type="math/tex; mode=display">\nu \gets \nu + \Delta\nu</script><p>BP算法基于梯度下降策略，以目标的负梯度方向对参数进行调整，对式(2)的误差$E_k$，给定学习率$\eta$,有</p><script type="math/tex; mode=display">\Delta\omega_{hj} = -\eta \frac{\partial E_k}{\partial\omega_{hj}} \tag{3}</script><p>注意到$\omega_{hj}$先影响到$j$个输出层神经元的输入值$\beta_j$，在影响到其输出值$\hat y^k_j$,然后在影响到$E_k$,有</p><script type="math/tex; mode=display">\frac{\partial E_k}{\partial\omega_{hj}} = \frac{\partial E_k}{\partial\hat y^k_j}\cdot\frac{\partial \hat y^k_j}{\partial\beta_j}\cdot\frac{\partial \beta_j}{\partial\hat y^k_j} \tag{4}</script><p>根据$\beta_j$的定义显然有</p><script type="math/tex; mode=display">\frac{\partial \beta_j}{\partial\hat y^k_j} = b_n \tag{5}</script><p>$Sigmoid$函数有一个很好的性质：</p><script type="math/tex; mode=display">f^{'}(x)=f(x)(1-f(x))</script><p>令$g_j=-\frac{\partial E_k}{\partial\hat y^k_j}\cdot\frac{\partial \hat y^k_j}{\partial\beta_j}$ ,则</p><script type="math/tex; mode=display">\begin{aligned}g_j&=-\frac{\partial E_k}{\partial\hat y^k_j}\cdot\frac{\partial \hat y^k_j}{\partial\beta_j} \\&=-(\hat y^k_j-y^k_j)f^{'}(\beta - \theta_j)\\&= \hat y^k_j(1-\hat y^k_j)(y^k_j-\hat y^k_j) \end{aligned}\tag{6}</script><p>将式(6)和式(5)代入式(4)，再代入式(3)可以得到：</p><script type="math/tex; mode=display">\Delta\omega_hj = \eta g_jb_h</script><p>类似的可以得到</p><script type="math/tex; mode=display">\Delta\theta_j=-\eta g_j</script><script type="math/tex; mode=display">\Delta \nu_ih = \eta e_hx_i</script><script type="math/tex; mode=display">\Delta\gamma_h=-\eta e_h</script><p>其中</p><script type="math/tex; mode=display">\begin{aligned}e_h&=-\frac{\partial E_k}{\partial b_h}\cdot\frac{\partial b_h}{\partial\alpha_h}\\&=-\sum^l_{j=1}\frac{\partial E_k}{\partial \beta_j}\cdot\frac{\partial \beta_j}{\partial b_h}f^{'}(\alpha_h-\gamma_h)\\&=\sum^l_{j=1}\omega_{hj}g_jf^{'}(\alpha_h-\gamma_h)\\&=b_h(1-b_h)\sum^l_{j=1}\omega_{hj}g_j\end{aligned}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;误差逆传播算法&quot;&gt;&lt;a href=&quot;#误差逆传播算法&quot; class=&quot;headerlink&quot; title=&quot;误差逆传播算法&quot;&gt;&lt;/a&gt;误差逆传播算法&lt;/h1&gt;&lt;p&gt;摘自机器学习-西瓜书-周志华&lt;/p&gt;
&lt;p&gt;部分内容为个人理解&lt;/p&gt;
&lt;p&gt;给定训练集$D={(x
      
    
    </summary>
    
      <category term="深度学习" scheme="http://www.gistime.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="神经网络" scheme="http://www.gistime.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="机器学习" scheme="http://www.gistime.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Django 使用教程</title>
    <link href="http://www.gistime.cn/2019/01/29/Django%20/"/>
    <id>http://www.gistime.cn/2019/01/29/Django /</id>
    <published>2019-01-29T03:19:53.000Z</published>
    <updated>2019-01-29T07:22:11.661Z</updated>
    
    <content type="html"><![CDATA[<h2 id="示例1：安装Django并创建简单项目"><a href="#示例1：安装Django并创建简单项目" class="headerlink" title="示例1：安装Django并创建简单项目"></a>示例1：安装Django并创建简单项目</h2><p>详情见<a href="https://docs.djangoproject.com/zh-hans/2.1/intro/tutorial01/" target="_blank" rel="noopener">https://docs.djangoproject.com/zh-hans/2.1/intro/tutorial01/</a></p><p>环境基础为windows10+anaconda3</p><h3 id="1、安装Django（版本2-1-5）"><a href="#1、安装Django（版本2-1-5）" class="headerlink" title="1、安装Django（版本2.1.5）"></a>1、安装Django（版本2.1.5）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Django==2.1.5</span><br></pre></td></tr></table></figure><h3 id="2、查看版本"><a href="#2、查看版本" class="headerlink" title="2、查看版本"></a>2、查看版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m django --version</span><br></pre></td></tr></table></figure><h3 id="3、创建项目"><a href="#3、创建项目" class="headerlink" title="3、创建项目"></a>3、创建项目</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">django-admin startproject mysite</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">项目的目录结构</span><br><span class="line">mysite/</span><br><span class="line">    manage.py</span><br><span class="line">    mysite/</span><br><span class="line">        __init__.py</span><br><span class="line">        settings.py</span><br><span class="line">        urls.py</span><br><span class="line">        wsgi.py</span><br></pre></td></tr></table></figure><p>目录说明</p><p>mysite：项目名，项目的容器。</p><p>manage.py:项目启动入口，用于与django内部进行交互</p><p>init.py:初始化文件</p><p>settings.py:项目配置信息</p><p>urls.py:项目中webapi的路由配置</p><p>wsgi.py:一个 WSGI 兼容的 Web 服务器的入口</p><h3 id="4、启动项目"><a href="#4、启动项目" class="headerlink" title="4、启动项目"></a>4、启动项目</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure><p>默认端口为127.0.0.1:8080,可以在runserver后添加自拟端口</p><h3 id="5、创建应用"><a href="#5、创建应用" class="headerlink" title="5、创建应用"></a>5、创建应用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py startapp polls</span><br></pre></td></tr></table></figure><h3 id="6、创建视图"><a href="#6、创建视图" class="headerlink" title="6、创建视图"></a>6、创建视图</h3><p>在polls/views.py中修改代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">"Hello, world. You're at the polls index."</span>)</span><br></pre></td></tr></table></figure><p>在polls文件夹下创建urls.py并添加代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">''</span>, views.index, name=<span class="string">'index'</span>),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>在mysite/urls.py中修改代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'polls/'</span>, include(<span class="string">'polls.urls'</span>)),</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>运行 python  manage.py runserver 并访问 localhost:8000/polls(不是 localhost:8000)，将会看到Hello, world. You’re at the polls index.</p><h2 id="示例2："><a href="#示例2：" class="headerlink" title="示例2："></a>示例2：</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;示例1：安装Django并创建简单项目&quot;&gt;&lt;a href=&quot;#示例1：安装Django并创建简单项目&quot; class=&quot;headerlink&quot; title=&quot;示例1：安装Django并创建简单项目&quot;&gt;&lt;/a&gt;示例1：安装Django并创建简单项目&lt;/h2&gt;&lt;p&gt;详情
      
    
    </summary>
    
      <category term="编程" scheme="http://www.gistime.cn/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="前端开发" scheme="http://www.gistime.cn/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Video Person Re-Identification</title>
    <link href="http://www.gistime.cn/2018/11/14/video%20person%20reid/"/>
    <id>http://www.gistime.cn/2018/11/14/video person reid/</id>
    <published>2018-11-14T10:37:53.000Z</published>
    <updated>2019-01-29T03:17:57.657Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://handong1587.github.io/deep_learning/2015/10/09/re-id.html" target="_blank" rel="noopener">Paper</a> <a href="http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html" target="_blank" rel="noopener">Datasets</a> <a href="https://github.com/KaiyangZhou/deep-person-reid" target="_blank" rel="noopener">Code1</a> <a href="https://github.com/jiyanggao/Video-Person-ReID" target="_blank" rel="noopener">Code2</a></p><h4 id="Leaderboard"><a href="#Leaderboard" class="headerlink" title="Leaderboard"></a>Leaderboard</h4><div class="table-container"><table><thead><tr><th>rank1/mAP</th><th>iLIDS-VID</th><th>PRID2011</th><th>MARS</th><th>DukeMTMC-VideoReID</th></tr></thead><tbody><tr><td><a href="#SCAN">SCAN</a></td><td>88.0/89.9</td><td>95.3/95.8</td><td>87.2/77.2</td><td>/</td></tr><tr><td><a href="#Co-attention">Co-attention</a></td><td>85.4/87.8</td><td>93.0/94.5</td><td>86.3/76.1</td><td>/</td></tr><tr><td><a href="3DCNNNon-local">3DCNN&amp;Non-local</a></td><td>81.3</td><td>91.2</td><td>84.3/77.0</td><td>/</td></tr><tr><td><a href="#STAN">STAN</a></td><td>80.2/</td><td>93.2/</td><td>82.3/65.8</td><td>/</td></tr><tr><td><a href="#RQEN">RQEN</a></td><td>77.1/</td><td>91.8/</td><td>77.83/71.14</td><td>/</td></tr></tbody></table></div><h5 id="RQEN-Region-based-Quality-Estimation-Network-for-Large-scale-Person-Re-identification"><a href="#RQEN-Region-based-Quality-Estimation-Network-for-Large-scale-Person-Re-identification" class="headerlink" title="(RQEN)Region-based Quality Estimation Network for Large-scale Person Re-identification"></a><span id="RQEN">(RQEN)Region-based Quality Estimation Network for Large-scale Person Re-identification</span></h5><p>paper:<a href="https://arxiv.org/abs/1711.08766" target="_blank" rel="noopener">https://arxiv.org/abs/1711.08766</a></p><p>code:<a href="https://github.com/sciencefans/Quality-Aware-Network" target="_blank" rel="noopener">https://github.com/sciencefans/Quality-Aware-Network</a></p><h5 id="ATAN-Diversity-Regularized-Spatiotemporal-Attention-for-Video-based-Person-Re-identification"><a href="#ATAN-Diversity-Regularized-Spatiotemporal-Attention-for-Video-based-Person-Re-identification" class="headerlink" title="(ATAN)Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identification"></a><span id="STAN">(ATAN)Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identification</span></h5><p>paper:<a href="https://arxiv.org/abs/1803.09882" target="_blank" rel="noopener">https://arxiv.org/abs/1803.09882</a></p><h5 id="Co-attention-Video-Person-Re-identification-with-Competitive-Snippet-similarity-Aggregation-and-Co-attentive-Snippet-Embedding"><a href="#Co-attention-Video-Person-Re-identification-with-Competitive-Snippet-similarity-Aggregation-and-Co-attentive-Snippet-Embedding" class="headerlink" title="(Co-attention)Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding"></a><span id="Co-attention">(Co-attention)Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding</span></h5><p>paper:<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Video_Person_Re-Identification_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Video_Person_Re-Identification_CVPR_2018_paper.pdf</a></p><h5 id="3DCNN-amp-Non-local-Video-based-Person-Re-identification-via-3D-Convolutional-Networks-and-Non-local-Attention"><a href="#3DCNN-amp-Non-local-Video-based-Person-Re-identification-via-3D-Convolutional-Networks-and-Non-local-Attention" class="headerlink" title="(3DCNN&amp;Non-local)Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attention"></a><span id="3DCNNNon-local">(3DCNN&amp;Non-local)Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attention</span></h5><p>paper: <a href="https://arxiv.org/abs/1807.05073" target="_blank" rel="noopener">https://arxiv.org/abs/1807.05073</a></p><h5 id="SCAN-Self-and-Collaborative-Attention-Network-for-Video-Person-Re-identification"><a href="#SCAN-Self-and-Collaborative-Attention-Network-for-Video-Person-Re-identification" class="headerlink" title="SCAN: Self-and-Collaborative Attention Network for Video Person Re-identification"></a><span id="SCAN">SCAN: Self-and-Collaborative Attention Network for Video Person Re-identification</span></h5><p>paper:<a href="https://arxiv.org/abs/1807.05688" target="_blank" rel="noopener">https://arxiv.org/abs/1807.05688</a></p><h5 id="Revisiting-Temporal-Modeling-for-Video-based-Person-ReID"><a href="#Revisiting-Temporal-Modeling-for-Video-based-Person-ReID" class="headerlink" title="Revisiting Temporal Modeling for Video-based Person ReID"></a>Revisiting Temporal Modeling for Video-based Person ReID</h5><p>paper:<a href="https://arxiv.org/abs/1805.02104" target="_blank" rel="noopener">https://arxiv.org/abs/1805.02104</a></p><p>code:<a href="https://github.com/jundet/Video-Person-ReID" target="_blank" rel="noopener">https://github.com/jundet/Video-Person-ReID</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://handong1587.github.io/deep_learning/2015/10/09/re-id.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Paper&lt;/a&gt; &lt;a href=&quot;http://robu
      
    
    </summary>
    
      <category term="行人再识别" scheme="http://www.gistime.cn/categories/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="行人再识别" scheme="http://www.gistime.cn/tags/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>机器学习课程——糖尿病预测</title>
    <link href="http://www.gistime.cn/2018/10/25/MLclass/"/>
    <id>http://www.gistime.cn/2018/10/25/MLclass/</id>
    <published>2018-10-25T13:36:57.000Z</published>
    <updated>2019-04-20T07:13:19.076Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机器学习课程——糖尿病预测"><a href="#机器学习课程——糖尿病预测" class="headerlink" title="机器学习课程——糖尿病预测"></a>机器学习课程——糖尿病预测</h1><p> <a href="https://github.com/jundet/ML" target="_blank" rel="noopener">code</a></p><h4 id="具体流程为"><a href="#具体流程为" class="headerlink" title="具体流程为"></a>具体流程为</h4><ol><li><p>数据预处理</p></li><li><p>模型构建</p></li><li><p>实验结果</p></li></ol><h3 id="1、数据预处理"><a href="#1、数据预处理" class="headerlink" title="1、数据预处理"></a>1、数据预处理</h3><p><img src="/2018/10/25/MLclass/数据处理.png" alt="数据处理"></p><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><p>对数据集进行划分和归一化等常规操作后观察到两种类别存在不平衡的问题，这会对模型的训练产生偏差。为了解决该问题使用生成对抗网络（GAN）进行训练并产生新的数据加入到训练数据集中以平衡两种类别。生成对抗网络（GAN）能够学习到原有数据集的分布情况，产生的数据能与原有数据保持相同的分布即新的数据可以在一定程度（GAN的设计与训练的好坏）上认为是真实的样本。</p><p><img src="/2018/10/25/MLclass/GAN.png" alt="GAN"></p><h3 id="2、模型构建"><a href="#2、模型构建" class="headerlink" title="2、模型构建"></a>2、模型构建</h3><p>1、分别使用神经网络（NN）、随机树（ET）、逻辑回归（Logistic）、支持向量机（SVM）、GradientBoosting（gdbt）、AdaBoost、XGBoost、LightGBM、CatBoost等模型对数据集进行训练和测试。</p><p>2、尝试使用单模型进行融合，使用融合后的模型对数据进行训练和测试。模型融合使用多数投票分类器。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/25/MLclass/融合.png" alt="融合" title="">                </div>                <div class="image-caption">融合</div>            </figure><h3 id="3、实验结果"><a href="#3、实验结果" class="headerlink" title="3、实验结果"></a>3、实验结果</h3><div class="table-container"><table><thead><tr><th></th><th>模型融合</th><th>神经网络</th><th>CatBoost</th></tr></thead><tbody><tr><td>accuracy</td><td>83.1%</td><td>82.1%</td><td>82.4%</td></tr><tr><td>F1-score</td><td>72.0%</td><td>70.2%</td><td>70.6%</td></tr></tbody></table></div><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/25/MLclass/模型融合.png" alt="模型融合" title="">                </div>                <div class="image-caption">模型融合</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/2018/10/25/MLclass/模型融合(GAN).png" alt="模型融合(GAN)" title="">                </div>                <div class="image-caption">模型融合(GAN)</div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;机器学习课程——糖尿病预测&quot;&gt;&lt;a href=&quot;#机器学习课程——糖尿病预测&quot; class=&quot;headerlink&quot; title=&quot;机器学习课程——糖尿病预测&quot;&gt;&lt;/a&gt;机器学习课程——糖尿病预测&lt;/h1&gt;&lt;p&gt; &lt;a href=&quot;https://github.c
      
    
    </summary>
    
      <category term="机器学习" scheme="http://www.gistime.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://www.gistime.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="生成对抗网络" scheme="http://www.gistime.cn/tags/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>基于局部和精细化分割的行人重识别</title>
    <link href="http://www.gistime.cn/2018/10/15/PCB/"/>
    <id>http://www.gistime.cn/2018/10/15/PCB/</id>
    <published>2018-10-15T10:37:53.000Z</published>
    <updated>2018-10-25T09:00:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>(PCB+RPP)Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)</p><p><a href="https://arxiv.org/abs/1711.09349v3" target="_blank" rel="noopener">Paper</a>,<a href="https://github.com/GenkunAbe/reID-PCB" target="_blank" rel="noopener">code1</a>,<a href="https://github.com/syfafterzy/PCB_RPP_for_reID" target="_blank" rel="noopener">code2</a></p><p>Market1501： rank1：93.8，mAP：81.6</p><p>PCB（Part-based Convolutional  Baseline）：基于局部信息能够获得细粒度特征，对人体的水平分割比较符合人体分布，在一定程度上保护有效信息源，使其不被割裂。</p><p>RPP（Refined Part Pooling）：实现了人体分割中的软分割，在原有水平分割的基础上再进行相应训练，融入对抗训练的思想使的再分割后的图像更加符合细粒度的特征提取，有效的解决了硬性分割带来的有效信息割裂的问题，保证了信息的完整性。</p><p><a href="https://zhuanlan.zhihu.com/p/31947809" target="_blank" rel="noopener">相关解读1</a> <a href="https://blog.csdn.net/Gavinmiaoc/article/details/80350613" target="_blank" rel="noopener">相关解读2</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;(PCB+RPP)Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arx
      
    
    </summary>
    
      <category term="行人再识别" scheme="http://www.gistime.cn/categories/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="多尺度" scheme="http://www.gistime.cn/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6/"/>
    
      <category term="行人再识别" scheme="http://www.gistime.cn/tags/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
      <category term="soft-attention" scheme="http://www.gistime.cn/tags/soft-attention/"/>
    
  </entry>
  
  <entry>
    <title>学习多粒度显著特征用于跨境追踪技术</title>
    <link href="http://www.gistime.cn/2018/10/10/MGN/"/>
    <id>http://www.gistime.cn/2018/10/10/MGN/</id>
    <published>2018-10-10T04:37:53.000Z</published>
    <updated>2018-10-10T05:11:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>(MGN)Learning Discriminative Features with Multiple Granularity for Person Re-Identification</p><p><a href="http://www.sohu.com/a/238041608_633698" target="_blank" rel="noopener">视频介绍</a> ,<a href="https://arxiv.org/abs/1804.01438" target="_blank" rel="noopener">Paper</a>,<a href="https://github.com/seathiefwang/MGN-pytorch" target="_blank" rel="noopener">code1</a>,<a href="https://github.com/levyfan/reid-mgn" target="_blank" rel="noopener">code2</a></p><p>Market1501： rank1：95.7，mAP：86.9</p><p>利用多粒度实现了对全局和局部信息特征的同时提取。其中全局特征模块中对人的整体特征进行的提取可以更好的关注人的整体结构，对图片进行2分和3分的分割对人的局部信息进行提取。该网络依赖ResNet，ResNet大大提高了准确率（ResNet50本身可以达到 Market1501： rank1：89.13，mAP：73.5）</p><p>多粒度的思想能充分提取特征。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;(MGN)Learning Discriminative Features with Multiple Granularity for Person Re-Identification&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.sohu.com/a/238041
      
    
    </summary>
    
      <category term="行人再识别" scheme="http://www.gistime.cn/categories/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="多尺度" scheme="http://www.gistime.cn/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6/"/>
    
      <category term="行人再识别" scheme="http://www.gistime.cn/tags/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>算法导论</title>
    <link href="http://www.gistime.cn/2018/10/08/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"/>
    <id>http://www.gistime.cn/2018/10/08/算法导论/</id>
    <published>2018-10-08T13:36:57.000Z</published>
    <updated>2019-01-29T03:17:57.677Z</updated>
    
    <content type="html"><![CDATA[<h1 id="算法导论"><a href="#算法导论" class="headerlink" title="算法导论"></a>算法导论</h1><h2 id="第一章-算法在计算中的应用"><a href="#第一章-算法在计算中的应用" class="headerlink" title="第一章 算法在计算中的应用"></a>第一章 算法在计算中的应用</h2><h3 id="1-2-作为一种技术的算法"><a href="#1-2-作为一种技术的算法" class="headerlink" title="1.2 作为一种技术的算法"></a>1.2 作为一种技术的算法</h3><h4 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h4><p>1.2-2 插入排序运行步数为$8n^2$步，而归并排序运行$64nlgn$ 步，问对哪些n值，插入排序优于归并排序？<br>    $8n^2 &lt; 64nlgn$，n=2,3</p><p>1.2.3 n最小值为何值时，运行时间为$100n^2$的一个算法在相同机器上快于运行时间为$2^n$ 的另一个算法？<br>    $100n^2  &lt; 2^n$,n=15</p><h4 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h4><p>1-1 （运行时间比较）假设求解问题的算法需要$f(n)$ 毫秒，对下表中每个函数$f(n)$ 和时间t，确定可以在时间t内求解的问题的最大规模n。</p><div class="table-container"><table><thead><tr><th></th><th>1秒钟</th><th>1分钟</th><th>1小时</th><th>1天</th><th>1月</th><th>1年</th><th>1世纪</th></tr></thead><tbody><tr><td>$lgn$</td><td>$10^4$</td><td>$6\times 10^5$</td><td>$3.6\times 10^7$</td><td>$8.64\times10^8$</td><td>$2.592\times10^{10}$</td><td>$3.1536\times10^{11}$</td><td>$3.1536\times10^{13}$</td></tr><tr><td>$\sqrt{n}$</td><td>$10^6$</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$n$</td><td>$10^3$</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$nlgn$</td><td>386</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$n^2$</td><td>31</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$n^3$</td><td>10</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$2^n$</td><td>9</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>$n!$</td><td>6</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h2 id="第二章-算法基础"><a href="#第二章-算法基础" class="headerlink" title="第二章 算法基础"></a>第二章 算法基础</h2><h3 id="2-1-插入排序"><a href="#2-1-插入排序" class="headerlink" title="2.1 插入排序"></a>2.1 插入排序</h3><h4 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSERTION-SORT(A)</span><br><span class="line">for j = 2 to A.length</span><br><span class="line">key = A[j]</span><br><span class="line">//inster A[j] into the sorted sequence A[1..j-1]</span><br><span class="line">i = j-1</span><br><span class="line">while i&gt;0 and A[i]&gt;key</span><br><span class="line">A[i+1] = A[i]</span><br><span class="line">i = i-1</span><br><span class="line">A[j+1] = key</span><br></pre></td></tr></table></figure><h4 id="python-实现"><a href="#python-实现" class="headerlink" title="python 实现"></a>python 实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertion_sort</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,len(A)):</span><br><span class="line">        key = A[j]</span><br><span class="line">        i = j<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span> i&gt;<span class="number">-1</span> <span class="keyword">and</span> A[i]&gt;key:</span><br><span class="line">            A[i+<span class="number">1</span>] = A[i]</span><br><span class="line">            i -= <span class="number">1</span></span><br><span class="line">        A[i+<span class="number">1</span>] = key</span><br><span class="line">    <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure><h4 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h4><p>2.1-2 重写INSERTION-SORT，使之按降序排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertion_sort</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,len(A)):</span><br><span class="line">        key = A[j]</span><br><span class="line">        i = j<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span> i&gt;<span class="number">-1</span> <span class="keyword">and</span> A[i]&lt;key: <span class="comment"># 将原来的A[i]&gt;k改为 A[i]&lt;k</span></span><br><span class="line">            A[i+<span class="number">1</span>] = A[i]</span><br><span class="line">            i -= <span class="number">1</span></span><br><span class="line">        A[i+<span class="number">1</span>] = key</span><br><span class="line"><span class="keyword">return</span> A</span><br></pre></td></tr></table></figure><p>2.1-3 考虑以下查找问题：<br>    输入：n个数的一个序列A=<a<sub>1&lt;/sub&gt;，a<sub>2</sub>,…,a<sub>n</sub>&gt;    和一个数v<br>    输出：当v=A[i]时输出下标i，当v不在A中时输出特殊值 NIL<br>    写出线性查找的伪代码，它扫描整个序列来查找v。使用一个循环不变是来证明你的算法正确性。确保你的循环不变式满足三个必要的性质。</a<sub></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">j = -1</span><br><span class="line">for i = 0 to A.length:</span><br><span class="line">if A[i] == v</span><br><span class="line">j = i</span><br><span class="line">break</span><br><span class="line">else:</span><br><span class="line">       i++</span><br><span class="line">if j == -1:</span><br><span class="line">return NIL</span><br><span class="line">else:</span><br><span class="line">return j</span><br></pre></td></tr></table></figure><p>2.1-4 考虑将将两个n位二进制整数加起来，这两个整数分别存储在两个n位数组中A和B中，这两个整数的和应该按照二进制形式存储在一个（n+1）元数组C中，写出伪代码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">z = 0</span><br><span class="line">for j = 1 to n：</span><br><span class="line">i = n - j</span><br><span class="line">m = A[i] + B[i] + z</span><br><span class="line">if m%2==0:</span><br><span class="line">c[i+1] = 0</span><br><span class="line">else:</span><br><span class="line">c[i+1] = 1</span><br><span class="line">if m&gt;1:</span><br><span class="line">z = 1</span><br><span class="line">else:</span><br><span class="line">z = 0</span><br><span class="line">j++</span><br></pre></td></tr></table></figure><h3 id="2-2-分析算法"><a href="#2-2-分析算法" class="headerlink" title="2.2 分析算法"></a>2.2 分析算法</h3><h5 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h5><p>2.2-1 用$\Theta$ 记号表示函数$n^3/1000 - 100n^2 -100n +3$</p><p>$\Theta(n^3)$</p><p>2.2-1 对储存在数组A中的n个数进行排序：首先找出A中最小元素并将其与A[1]中的元素进行交换。接着找出A中的次最小元素并将其与A[2]中的元素进行交换。对A中前n-1个圆度按照该方式继续，该算法叫做选择排序，写出其伪代码。用$\Theta$给出选择排序的最好情况与最坏情况运行的时间。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for i = 0 to A.length      </span><br><span class="line">min = a[i]</span><br><span class="line">tempj = i</span><br><span class="line">for j = A.length - i to A.length  </span><br><span class="line">if a[j] &lt; min:</span><br><span class="line">min = a[j]</span><br><span class="line">tempj = j</span><br><span class="line">temp = a[i]</span><br><span class="line">a[i] = min</span><br><span class="line">a[j] = temp</span><br></pre></td></tr></table></figure><p>最好情况时即已经排序好，则为$\Theta(n)$，最坏的情况为逆序，则为$\Theta(n^2)$</p><p>2.2-3 线性查找平均需要检查输入序列的多少个元素，最坏的情况又如何？</p><p>平均查找需要$\theta(n/2)$,最坏需要$\theta(n)$</p><h3 id="2-3-设计算法"><a href="#2-3-设计算法" class="headerlink" title="2.3 设计算法"></a>2.3 设计算法</h3><h4 id="2-3-1-分治法"><a href="#2-3-1-分治法" class="headerlink" title="2.3.1 分治法"></a>2.3.1 分治法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">MERGE(A, p, q, r)</span><br><span class="line">n1 = q - p + 1</span><br><span class="line">n2 = r - q</span><br><span class="line">let L[1..n1 + 1] and R[1..n2 + 1] by new arrays</span><br><span class="line">for i = 1 to n1</span><br><span class="line">L[i] = A[p + i -1]</span><br><span class="line">for j =  1 to n2</span><br><span class="line">R[j] = A[q + j]</span><br><span class="line">L[n1 + 1] = &amp; infin;</span><br><span class="line">L[n2 + 1] = &amp; infin;</span><br><span class="line">i = 1</span><br><span class="line">j = 1</span><br><span class="line">for k = p to r</span><br><span class="line">if L[i] &lt;= R[j]</span><br><span class="line">A[k] = L[i]</span><br><span class="line">i = i + 1</span><br><span class="line">else </span><br><span class="line">A[k] = R[j]</span><br><span class="line">j = j + 1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">MEGRE-SORT(A, p, r)</span><br><span class="line">if p &lt; r</span><br><span class="line">q = [(p+r)/2]</span><br><span class="line">MEGRE-SORT(A, p, q)</span><br><span class="line">MEGRE-SORT(A, q+1, r)</span><br><span class="line">MERGE(A, p, q, r)</span><br></pre></td></tr></table></figure><p>归并排序算法python实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sort</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="comment"># 分</span></span><br><span class="line">    <span class="keyword">if</span> len(A)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    middle = len(A)//<span class="number">2</span></span><br><span class="line">    left = sort(A[:middle])</span><br><span class="line">    right = sort(A[middle:])</span><br><span class="line">    <span class="comment"># 治</span></span><br><span class="line">    <span class="keyword">return</span> merge(left,right)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 治</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left,right)</span>:</span></span><br><span class="line">    c = []</span><br><span class="line">    h = j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> j&lt;len(left) <span class="keyword">and</span> h&lt;len(right):</span><br><span class="line">        <span class="keyword">if</span> left[j]&lt;right[h]:</span><br><span class="line">            c.append(left[j])</span><br><span class="line">            j+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c.append(right[h])</span><br><span class="line">            h+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> j==len(left):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> right[h:]:</span><br><span class="line">            c.append(i)</span><br><span class="line">    <span class="keyword">if</span> h==len(right):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> left[j:]:</span><br><span class="line">            c.append(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure><h2 id="第3章-函数的增长"><a href="#第3章-函数的增长" class="headerlink" title="第3章 函数的增长"></a>第3章 函数的增长</h2><h2 id="第7章-快速排序"><a href="#第7章-快速排序" class="headerlink" title="第7章 快速排序"></a>第7章 快速排序</h2><h3 id="7-1-快速排序的描述"><a href="#7-1-快速排序的描述" class="headerlink" title="7.1 快速排序的描述"></a>7.1 快速排序的描述</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">QUICKSOURT(A, p, r)</span><br><span class="line">if p&lt;r</span><br><span class="line">q = PARTITION(A, p, r)</span><br><span class="line">QUICKSOURT(A, p, q-1)</span><br><span class="line">QUICKSOURT(A, q+1, r)</span><br><span class="line"></span><br><span class="line">PARTITION(A, p, r)</span><br><span class="line">x = A[r]</span><br><span class="line">i = p-1</span><br><span class="line">for j=p to r-1</span><br><span class="line">if A[j]&lt;x</span><br><span class="line">i = i+1</span><br><span class="line">exchange A[i] with A[j]</span><br><span class="line">exchange A[i+1] with A[r]</span><br></pre></td></tr></table></figure><p>快速排序的python实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quicksort</span><span class="params">(A, p, r)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> p &lt; r:</span><br><span class="line">        q = partition(A, p, r)</span><br><span class="line">        quicksort(A, p, q<span class="number">-1</span>)</span><br><span class="line">        quicksort(A, q+<span class="number">1</span>, r)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(A, p, r)</span>:</span></span><br><span class="line">    x = A[r]</span><br><span class="line">    i = p<span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(p, r):</span><br><span class="line">        <span class="keyword">if</span> A[j]&lt;=x:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            A[i], A[j] = A[j], A[i] <span class="comment"># 交换位置，将小于x的放到左边，i是划分的位置点</span></span><br><span class="line">    A[i+<span class="number">1</span>], A[r] = A[r], A[i+<span class="number">1</span>]  <span class="comment"># 最后将主元x放到两个序列中间</span></span><br><span class="line">    <span class="keyword">return</span> i+<span class="number">1</span></span><br></pre></td></tr></table></figure></p><h3 id="7-2-快速排序的性能"><a href="#7-2-快速排序的性能" class="headerlink" title="7.2 快速排序的性能"></a>7.2 快速排序的性能</h3><p>1、最坏情况划分</p><p>当每次划分的两个子问题分别含有n-1个元素和0个元素时，此时快速排序的时间复杂度为$O(n^2)$</p><p>2、最好情况划分</p><p>在最平衡划分时每个子问题的规模都不大于n/2，此时时间复杂度为$O(nlgn)$</p><p>3、平衡的划分</p><p>最一般的情况下，两个子问题都不是最坏的情况也不是最平衡时，时间复杂度同样为$O(nlgn)$</p><h3 id="7-3-快速排序的随机化版本"><a href="#7-3-快速排序的随机化版本" class="headerlink" title="7.3 快速排序的随机化版本"></a>7.3 快速排序的随机化版本</h3><p>在上面的快速排序中主元每次都是取A[r]，随机化的版本则是每次随机化的选取数组中的一个元素作为主元，这样会使得数组的划分更为均衡化。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">RANDOMIZED-PARTITION(A, p, r)</span><br><span class="line">i = RANDOM(p, r)</span><br><span class="line">exchange A[r] with A[i]</span><br><span class="line">return PARTITION(A, p, r)</span><br><span class="line"># 随机化的快速排序不在调用PARTITION,而是调用RANDOMIZED-PARTITION</span><br><span class="line">RANDOMIZED-QUICKSOURT(A, p, r)</span><br><span class="line">if p&lt;r</span><br><span class="line">q = RANDOMIZED-PARTITION(A, p, r)</span><br><span class="line">RANDOMIZED-QUICKSOURT(A, p, q-1)</span><br><span class="line">RANDOMIZED-QUICKSOURT(A, q+1, r)</span><br></pre></td></tr></table></figure><p>随机化的快速排序python实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomzed_quicksort</span><span class="params">(A, p, r)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> p &lt; r:</span><br><span class="line">        q = randomzed_(A, p, r)</span><br><span class="line">        randomzed_quicksort(A, p, q<span class="number">-1</span>)</span><br><span class="line">        randomzed_quicksort(A, q+<span class="number">1</span>, r)</span><br><span class="line">        </span><br><span class="line"><span class="comment">#随机化过程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomzed_</span><span class="params">(A, p, r)</span>:</span></span><br><span class="line">    i = random.randint(p, r)</span><br><span class="line">    A[r],A[i] = A[i],A[r]</span><br><span class="line">    <span class="keyword">return</span> partition(A, p, r)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(A, p, r)</span>:</span></span><br><span class="line">    x = A[r]</span><br><span class="line">    i = p<span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(p, r):</span><br><span class="line">        <span class="keyword">if</span> A[j]&lt;=x:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            A[i], A[j] = A[j], A[i]</span><br><span class="line">    A[i+<span class="number">1</span>], A[r] = A[r], A[i+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> i+<span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;算法导论&quot;&gt;&lt;a href=&quot;#算法导论&quot; class=&quot;headerlink&quot; title=&quot;算法导论&quot;&gt;&lt;/a&gt;算法导论&lt;/h1&gt;&lt;h2 id=&quot;第一章-算法在计算中的应用&quot;&gt;&lt;a href=&quot;#第一章-算法在计算中的应用&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="算法" scheme="http://www.gistime.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://www.gistime.cn/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
